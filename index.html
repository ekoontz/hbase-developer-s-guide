<html>
  <head>
    <!-- CSS : implied media="all" -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/hbase_dev_guide.css">
    
    <!-- For the less-enabled mobile browsers like Opera Mini -->
    <link rel="stylesheet" media="handheld" href="css/handheld.css?v=1">
    <title>HBase Dev Guide</title>
  </head>
  <body>
    <h1 "text-align:center;width:100%;float:left">HBase Dev Guide</h1>
    <h4>Author: Eugene Koontz et. al.</h4>
    <h1>Introduction</h1>
    <p>This guide is intended to help you get started with developing
    with Hbase.</p>

    <h1 id="dependencies">Dependencies</h1>
    
    <p>HBase typically runs on large clusters of servers, but to get
    started developing, you really only need one linux server
    instance. The installed package base is fairly small. Below, I
    analyze the dependencies according to machine roles.</p>

    <h2>Zookeeper role</h2>

    <p>Unless you are doing development on Zookeeper, just run
    zookeeper on the same server instance used for
    the <a href="#masterrole">Master role</a>.</p>

    <h2>Slave role</h2>

    <p>The slave runs the regionserver.</p>

    <ul>
      <li>opensshd</li>
      <li>git (<code>apt-get install git-core</code>)</li>
      <li>JDK (<code>apt-get install default-jdk</code>)</li>
      <li>Apache Maven (<code>apt-get install maven2</code>)</li>
      <li>krb5-user (if using Kerberos)</li>
      <li>ntpdate</li>
    </ul>

    <h2 id="masterrole">Master role</h2>

    <p>The master runs the Hbase server. Also, you might want to run
    Zookeeper there. Also if you want to develop with Kerberos, you
    might as well run the Kerberos Key KDC and Admin servers, too. On
    a real cluster, you'd run these separately, but this is to
    simplify things so that you can concentrate on HBase development.</p>

    <p>The master role requires everything from the Slave role
    plus:</p>
    <ul>
      <li>ntpd</li>
      <li>bind9</li>
      <li>krb5-kdc (if using Kerberos)</li>
      <li>krb5-admin-server (if using Kerberos)</li>
    </ul>

    <p>If you have a reliable connection to existing DNS and NTPd
    servers, you can skip ntpd and bind9. Personally I am sometimes
    traveling and I like to keep my VirtualBox cluster running when
    I'm disconnected from the Internet.</p>


    <h2>Dependencies: Remarks</h2>

    <p>As stated above, to get started with Hbase development, you only really need to
    have one machine that functions in both slave and master roles,
    but keep in mind that real Hbase clusters will have one master and
    many slaves.</p>

    <p>The above lists are only a small subset of what HBase
      needs, but everything else will be pulled in when we run Maven
      (see <b>Compilation</b> below), it will pull in all of the
      remaining prerequisites and store them in
      your <code>~/.m2</code> directory.
    </p>
    
    <p> Note that ubuntu's <code>default-jdk</code> installs OpenJDK,
      although Hbase officially recommends what people call the
      "<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk6-jsp-136632.html">Sun
      JDK</a>", although now it's owned by Oracle.</p>
    
    <p> I would like to do a more thorough analysis of the
      dependency graph in order to make the image and
      comprehensible as possible. It might be that you could start with a very small linux image, smaller than the default Debian server install.</p>

    <p>Note however that Maven itself requires quite a lot in order to
      install it. Here is the dependency graph
      for <code>maven2</code>: <br/>(
      <a href="maven2.png"><code>.png</code></a>,
      <a href="maven2.dot"><code>.dot</code></a>). 
    </p>


    <h1>VirtualBox</h1>
    <h2>VBox From Scratch</h2>
    <p><i>This section takes its name from the <a href="http://linuxfromscratch.org">similarly-named Linux distribution</a></i>.</p>
    <p>
      It is a good learning exercise to make your own Linux
      images. Create both "master" and "slave" images using the dependency lists for each shown in <a href="#dependencies">Dependencies</a>.
    </p>

    <div style="display:none">
      <!-- hide 'til working.. 
    <h2>Eugene's Virtualbox images download</h2>
      
    <p>(add link to virtualbox images..hopefully won't be too
      huge to host somewhere..)</p>
-->
    </div>
    <h1>Amazon EC2</h1>

    <p>Start with a recent Ubuntu such as <code>ami-04aa5f6d</code>.</p>

    <h1>Kerberos integration (optional)</h1>

    <h2>Setup</h2>
    <h3>Realm and Admin Server</h3>
    <p>You could install the Realm and Admin server on separate
    servers, but we'll just install them both on one for simplicity of
    explanation. Make sure your designated server has the related
    Kerberos server-related software installed (see <a href="#masterrole">Dependencies/Master role</a>).
    </p>

    <img src="realm_servers.png"/>
    <img src="realm.png"/>
    <img src="admin_server.png"/>
    
    <h3>Clients</h3>
    <p>Do this on all machines in your cluster that you will host your
    datanodes and regionservers.</p>

    <h1>HDFS Compilation</h1>

      <h2>Hadoop Git repository</h2>

      <p>Substitute your github username for <code>myuser</code> below:</p>

      <pre class="block">
	git clone http://github.com/myuser/hadoop-common
	git clone http://github.com/myuser/hadoop-hdfs
      </pre>

      <h1>HDFS Startup</h1>
      
      <h2>Authentication (optional)</h2>
      
    <p>This is required if you want to use Secure Hadoop and Secure HBase.</p>
    
    <h1>HDFS Test</h1>

    <p>Check to make sure your HDFS installation is working:</p>

    <pre class="block session">
ekoontz@ubuntu:~/hadoop$ bin/hadoop fs -lsr  hdfs://ubuntu.foofers.org/
ekoontz@ubuntu:~/hadoop$ bin/hadoop fs -mkdir  hdfs://ubuntu.foofers.org/foo
ekoontz@ubuntu:~/hadoop$ bin/hadoop fs -lsr  hdfs://ubuntu.foofers.org/
drwxr-xr-x   - ekoontz supergroup          0 2010-09-14 20:11 /foo
ekoontz@ubuntu:~/hadoop$ 
    </pre>
    
    <h2>Authentication (optional)</h2>
    
    <h1>HBase Compilation</h1>
      
      <h2>HBase Git repository</h2>

      <p>
      Substitute your github username for <code>myuser</code> below:
      </p>

      <pre class="block">
	git clone http://github.com/myuser/hbase
      </pre>

      <h2>HBase Startup</h2>

      <h3 id="devmode">Hadoop development <code>CLASSPATH</code> setting</h3>

      <p>This step allows you to control your Hadoop environment. For
      example, if you want to develop with Secure Hadoop, you'll want
      to explore the Hadoop/Kerberos communication, so you'll want to
      make sure that HBase is using the Hadoop that you're looking at
      in your Hadoop source directory (above)</p>

      <p>Add the following to your bin/hbase:</p>

      <pre class="block">
	if [ "$DEV_MODE" = "1" ] ; then
            CLASSPATH=~/hadoop-common/build/classes:~/hadoop-hdfs/build/classes:$CLASSPATH
	fi
      </pre>

      <h1>Development Cycle</h1>
      
      <p>Your development session with Hbase might look something like
      the following. Suppose you are working on developing a feature
      on the HBase Master's functionality.</p>

      <ol>
	<li><a href="#edit">edit code</a></li>
	<li><a href="#compile">compile</a></li>
	<li><a href="#run">start up regionserver</a> with <a href="#devmode">DEV_MODE=1</a></li>
	<li><a href="#run">start up master</a> with <a href="#devmode">DEV_MODE=1</a> and with the appropriate <a href="#attach">JVM settings to enable attachment</a>: it waits for for a debugger to attach to it.</li>
	<li>attach to master with debugger: it starts running and connects to zookeeper and the regionserver.</li>
	<li>set some breakpoints in debugger</li>
	<li>cause something to happen that causes the Master to execute within the code where you've set breakpoints. For example, if you've set some breakpoints in <code>HMaster:CreateTable()</code>, you might start up a <code>hbase shell</code> and then do a <code>create table</code>.</li>
	<li>wait for breakpoint to be hit in debugger</li>
	<li>step through code</li>
	<li>based on your runtime debugging inspection, decide what you want to change in the code</li>
	<li>kill the master and regionserver by doing control-C in each service's shell.</li>
	<li>if desired, <a href="#reinit">re-initialize the <code>hbase/</code> directory in HDFS</a>.
	<li>goto step 1</li>
      </ol>

      <h2 id="edit">Editing code</h2>

      <p>Use whatever editor you like but you should respect
      the <a href="">Hbase coding conventions</a>. Here are some links
      to documentation for various popular editors and how to
      configure them to respect these conventions.</p>

      <h2 id="compile">Compilation</h2>

      <p>
      In a shell, you can leave the following running while you work on your code:
      </p>

      <pre class="block">
while ( true ) do mvn compile && sleep 5 ; done
      </pre>

      <p>This ensures that you always have the latest code compiled and ready to run, and you'll notice compiler errors as you follow the output in one window, while editing your code in another window.</p>

      <p>Note that we do only <code>mvn compile</code>: only the <code>.class</code>es are generated, not <code>.jar</code>s.

	<h2 id="run">Running Hbase daemons</h2>

	<h3>Master</h3>
	<pre class="block session">
	  bin/hbase master start
	</pre>

	<h3>Regionserver</h3>
	<pre class="block session">
	  bin/hbase regionserver start
	</pre>

      <p>
	For development purposes, you only need one master and one
	regionserver. Each of these should be run in a separate shell.
	If you press <code>control-C</code> in one of these shells,
	you'll send a terminate signal to the respective service,
	which is good, so that you can easily stop and start the service</a>.

      <h2 id="reinit">Reinitialize <code>hbase/</code></h2>
      
      <p>You may from time to time want to wipe your HBase data directory (on HDFS) clean in between debugging runs. Here's how:</p>
      
      <pre class="block session">
ekoontz@ubuntu:~/hadoop$ bin/hadoop fs -rmr hdfs://ubuntu.foofers.org/hbase
      </pre>

      <h1>Runtime inspection of HBase</h1>
    <p>
      I prefer <a href="http://www.jetbrains.com/idea/">Intellij IDEA</a> rather than <a href="http://eclipse.org">Eclipse</a>, but would welcome
      someone writing an Eclipse guide and adding it here (using
      CC:attribute licence).
    </p>
        <h2>Intellij</h2>


        <h3 id="attach">Intellij: Attaching to remote instances</h3>
   
	<p>
	Intellij uses the Java debug machinery (enabled with):

	<pre class="block">
	  -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5006
	</pre>
	
	<p>
	to interactively debug Java processes running on remote
	machines. This is great because it lets you run your desktop
	operating system of choice (be it Mac OS X, Linux, or Windows)
	as your development environment, but still run your compiled
	runtime on Linux, which is required if you want to run HBase
	according to its <a href="http://hbase.org/">official
	Recommendations</a>.
	</p>

	<p>Note, however, that you will not be able to compile within
	Intellij: you must open a shell on the machine you want to run
	HBase on, and run <code>mvn compile</code> there.
	</p>

	<h1>Automated Testing</h1>

	<p>As you add new functionality to Hbase, be sure to add tests
	to the <code>src/tests</code> directory, and to make sure
	existing tests pass, using <code>mvn test</code>.</p>

	<p>Let's say you've just added a new class, <code>org.apache.hadoop.hbase.ipc.foo</code>. Your test should probably go in <code>hbase/src/test/java/ipc/TestFoo.java</code>. You'll be iteratively running your test and want to only run that test until it's ready to commit. To cause Maven to only run your test, you would do:</p>

	<pre class="block">
	  mvn -Dtest=TestFoo test
	</pre>

	<h2>Using EC2 for testing</h2>
	<p>Running all unit tests takes a long time; therefore, you
	might want a fast, dedicated server, or on Amazon EC2 large
	(or better) instance.</p>


  </body>
</html>
