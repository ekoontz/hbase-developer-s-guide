<html>
  <head>
    <!-- CSS : implied media="all" -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/hbase_dev_guide.css">
    
    <!-- For the less-enabled mobile browsers like Opera Mini -->
    <link rel="stylesheet" media="handheld" href="css/handheld.css?v=1">
    <title>HBase Dev Guide</title>
  </head>
  <body>
    <h1 style="text-align:center;width:100%;float:left">HBase Dev Guide</h1>
    <h4>Author: Eugene Koontz et. al.</h4>
    <h1>Introduction</h1>
    <p>This guide is intended to help you get started with developing
    with Hbase.</p>
    <p>Please note: this is intended to help you set up HBase on your
    own workstation for development, experimentation, education,
    etc. It's not for setting up a large-scale production ready HBase
    cluster. There is already <a href="http://hbase.org/">a lot of
    good documentation</a> for setting up production HBase
    clusters.</p>

    <div class="figure">
      <h3>HBase Development Node Stacks</h3>
      <table>
        <tr>
          <th colspan="2">master</th>

          <th>slave</th>
        </tr>
        <tr>
          <td colspan="2">HBase master</td>
          <td>HBase regionserver</td>
        </tr>
        <tr>
          <td>HDFS namenode</td>
          <td>Zookeeper</td>

          <td>HDFS datanode</td>
        </tr>

        <tr>
          <td colspan="2">NFS server</td>

          <td>NFS client</td>
        </tr>

        <tr>
          <td>Kerberos Ticket Server</td>
          <td>Kerberos Admin Server</td>

          <td>Kerberos client APIs</td>
        </tr>

        <tr>
          <td colspan="2">NTP server</td>
          <td>NTP client APIs</td>
        </tr>

        <tr>
          <td colspan="2">DNS server</td>
          <td>DNS client APIs</td>
        </tr>


      </table>
    </div>


    <h1>VirtualBox</h1>
    <h2>VBox From Scratch</h2>
    <p><i>This section takes its name from the <a href="http://linuxfromscratch.org">similarly-named Linux distribution</a></i>.</p>
    <p>
      It is a good learning exercise to make your own Linux
      images. Create both "master" and "slave" images using the dependency lists for each shown in <a href="#dependencies">Dependencies</a>.
    </p>

    <div style="display:none">
      <!-- hide 'til working.. 
    <h2>Eugene's Virtualbox images download</h2>
      
    <p>(add link to virtualbox images..hopefully won't be too
      huge to host somewhere..)</p>
-->
    </div>
    <h1>Amazon EC2</h1>

    <p>Start with a recent Ubuntu such as <code>ami-04aa5f6d</code>.</p>

    <h1 id="dependencies">Dependencies</h1>
    
    <p>HBase typically runs on large clusters of servers, but to get
    started developing, you really only need one linux server
    instance. The installed package base is fairly small. Below, I
    analyze the dependencies according to machine roles.</p>

    <h2>Zookeeper role</h2>

    <p>Unless you are doing development on Zookeeper, just run
    zookeeper on the same server instance used for
    the <a href="#masterrole">Master role</a>.</p>

    <h2>Slave role</h2>

    <p>The slave runs the regionserver.</p>

    <ul>
      <li>opensshd</li>
      <li>git (<code>apt-get install git-core</code>)</li>
      <li>JDK (<code>apt-get install default-jdk</code>)</li>
      <li>Apache Maven (<code>apt-get install maven2</code>)</li>
      <li>krb5-user (if using Kerberos)</li>
      <li>ntpdate</li>
    </ul>

    <h2 id="masterrole">Master role</h2>

    <p>The master runs the Hbase server. Also, you might want to run
    Zookeeper there. Also if you want to develop with Kerberos, you
    might as well run the Kerberos Key KDC and Admin servers, too. On
    a real cluster, you'd run these separately, but this is to
    simplify things so that you can concentrate on HBase development.</p>

    <p>The master role requires everything from the Slave role
    plus:</p>
    <ul>
      <li>ntpd</li>
      <li>bind9</li>
      <li>krb5-kdc (if using Kerberos)</li>
      <li>krb5-admin-server (if using Kerberos)</li>
    </ul>

    <p>If you have a reliable connection to existing DNS and NTPd
    servers, you can skip ntpd and bind9. Personally I am sometimes
    traveling and I like to keep my VirtualBox cluster running when
    I'm disconnected from the Internet.</p>


    <h2>Dependencies: Remarks</h2>

    <p>As stated above, to get started with Hbase development, you only really need to
    have one machine that functions in both slave and master roles,
    but keep in mind that real Hbase clusters will have one master and
    many slaves.</p>

    <p>The above lists are only a small subset of what HBase
      needs, but everything else will be pulled in when we run Maven
      (see <b>Compilation</b> below), it will pull in all of the
      remaining prerequisites and store them in
      your <code>~/.m2</code> directory.
    </p>
    
    <p> Note that ubuntu's <code>default-jdk</code> installs OpenJDK,
      although Hbase officially recommends what people call the
      "<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk6-jsp-136632.html">Sun
      JDK</a>", although now it's owned by Oracle.</p>
    
    <p> I would like to do a more thorough analysis of the
      dependency graph in order to make the image and
      comprehensible as possible. It might be that you could start with a very small linux image, smaller than the default Debian server install.</p>

    <p>Note however that Maven itself requires quite a lot in order to
      install it. Here is the dependency graph
      for <code>maven2</code>: <br/>(
      <a href="maven2.png"><code>.png</code></a>,
      <a href="maven2.dot"><code>.dot</code></a>). 
    </p>

    <h1>Kerberos integration (optional)</h1>

    <h2>Setup</h2>
    <h3>Realm and Admin Server</h3>
    <p>You could install the Realm and Admin server on separate
    servers, but we'll just install them both on one for simplicity of
    explanation. Make sure your designated server has the related
    Kerberos server-related software installed (see <a href="#masterrole">Dependencies/Master role</a>).
    </p>

    <img src="realm_servers.png"/>
    <img src="realm.png"/>
    <img src="admin_server.png"/>
    
    <h3>Clients</h3>
    <p>Do this on all machines in your cluster that you will host your
    datanodes and regionservers.</p>

    <h1>HDFS Compilation</h1>

      <h2>Hadoop Git repository</h2>

      <p>Substitute your github username for <code>myuser</code> below:</p>

      <pre class="block session">
	[~]$ <span class="input">git clone http://github.com/myuser/hadoop-common</span>
        <span class="output">git output</span>
        [~]$ <span class="input">git clone http://github.com/myuser/hadoop-hdfs</span>
        <span class="output">git output</span>
      </pre>

      <h1>HDFS Startup</h1>
      
      <h2>Authentication (optional)</h2>
      
    <p>This is required if you want to use Secure Hadoop and Secure HBase.</p>
    
    <h1>HDFS Test</h1>

    <p>Check to make sure your HDFS installation is working:</p>

    <pre class="block session">
[~/hadoop] $ <span class="input">bin/hadoop fs -lsr hdfs://namenode/</span>
[~/hadoop] $ <span class="input">bin/hadoop fs -mkdir hdfs://namenode/foo</span>
ekoontz@ubuntu:~/hadoop$ <span class="input">bin/hadoop fs -lsr hdfs://namenode/</span>
drwxr-xr-x   - ekoontz supergroup          0 2010-09-14 20:11 /foo
[~/hadoop] $ <span class="input">bin/hadoop dfsadmin -fs hdfs://namenode/   -report</span>
Configured Capacity: 23296315392 (21.7 GB)
Present Capacity: 9946144768 (9.26 GB)
DFS Remaining: 9946058752 (9.26 GB)
DFS Used: 86016 (84 KB)
DFS Used%: 0%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0

-------------------------------------------------
Datanodes available: 3 (3 total, 0 dead)

Name: 192.168.56.20:50010
Decommission Status : Normal
Configured Capacity: 7765438464 (7.23 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 3714699264 (3.46 GB)
DFS Remaining: 4050710528(3.77 GB)
DFS Used%: 0%
DFS Remaining%: 52.16%
Last contact: Wed Sep 22 00:30:29 PDT 2010


Name: 192.168.56.30:50010
Decommission Status : Normal
Configured Capacity: 7765438464 (7.23 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 2648248320 (2.47 GB)
DFS Remaining: 5117161472(4.77 GB)
DFS Used%: 0%
DFS Remaining%: 65.9%
Last contact: Wed Sep 22 00:30:28 PDT 2010


Name: 192.168.56.10:50010
Decommission Status : Normal
Configured Capacity: 7765438464 (7.23 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 6987223040 (6.51 GB)
DFS Remaining: 778186752(742.14 MB)
DFS Used%: 0%
DFS Remaining%: 10.02%
Last contact: Wed Sep 22 00:30:28 PDT 2010

    </pre>
      
    
    <h2>Authentication (optional)</h2>
    
    <h1>Zookeeper</h1>
    <h2>Compilation</h2>
    <pre class="block session">
ekoontz@zookeeper:~$ <span class="input">git clone http://github.com/apache/zookeeper.git</span>
ekoontz@zookeeper:~$ <span class="input">cd zookeeper</span>
ekoontz@zookeeper:~$ <span class="input">ant jar</span>
...
jar:
      [jar] Building jar: /home/ekoontz/zookeeper/build/zookeeper-3.4.0.jar

BUILD SUCCESSFUL
Total time: 27 seconds
ekoontz@zookeeper:~$ 
    </pre>
                               
    <h2>Configuration</h2>
    <pre class="block session">
ekoontz@zookeeper:~$ <span class="input">emacs conf/zoo.cfg</span>
ekoontz@zookeeper:~/zookeeper$ <span class="input">cat conf/zoo.cfg</span>
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/ekoontz/zk-data
clientPort=2181
clientPortAddress=zookeeper
    </pre>

    <h2>Startup</h2>
    <pre class="block session">
ekoontz@zookeeper:~/zookeeper$ <span class="input">bin/zkServer.sh start</span>
    </pre>

    <h2>Test</h2>
    <pre class="block session">
ekoontz@ekoontz:~$ <span class="input">telnet zookeeper 2181</span>
Trying 192.168.56.10...
Connected to ubuntu.foofers.org.
Escape character is '^]'.
ruok
imokConnection closed by foreign host.
ekoontz@ekoontz:~$ 
    </pre>

    <h1>HBase Compilation</h1>
      
      <h2>HBase Git repository</h2>

      <p>
      Substitute your github username for <code>myuser</code> below:
      </p>

      <pre class="block session">
	<span class="input">git clone http://github.com/myuser/hbase</span>
      </pre>

      <h2>HBase Startup</h2>

      <h3 id="devmode">Hadoop development <code>CLASSPATH</code> setting</h3>

      <p>This step allows you to control your Hadoop environment. For
      example, if you want to develop with Secure Hadoop, you'll want
      to explore the Hadoop/Kerberos communication, so you'll want to
      make sure that HBase is using the Hadoop that you're looking at
      in your Hadoop source directory (above)</p>

      <p>Add the following to your bin/hbase:</p>

      <pre class="block">
	if [ "$DEV_MODE" = "1" ] ; then
            CLASSPATH=~/hadoop-common/build/classes:~/hadoop-hdfs/build/classes:$CLASSPATH
	fi
      </pre>

      <h2 id="config">Configuration settings</h2>
     

    <p>Please see the following gist which shows configuration changes for both hbase-site.xml and hbase-env.sh.</p>
    <div class="gist">
      <script src="http://gist.github.com/626611.js"> </script>
    </div>

      <h1>Development Cycle</h1>
      
      <p>Your development session with Hbase might look something like
      the following. Suppose you are working on developing a feature
      on the HBase Master's functionality.</p>

      <ol>
	<li><a href="#edit">edit code</a></li>
	<li><a href="#compile">compile</a></li>
	<li><a href="#run">start up regionserver</a> with <a href="#devmode">DEV_MODE=1</a></li>
	<li><a href="#run">start up master</a> with <a href="#devmode">DEV_MODE=1</a> and with the appropriate <a href="#attach">JVM settings to enable attachment</a>: it waits for for a debugger to attach to it.</li>
	<li>attach to master with debugger: it starts running and connects to zookeeper and the regionserver.</li>
	<li>set some breakpoints in debugger</li>
	<li>cause something to happen that causes the Master to execute within the code where you've set breakpoints. For example, if you've set some breakpoints in <code>HMaster:CreateTable()</code>, you might start up a <code>hbase shell</code> and then do a <code>create table</code>.</li>
	<li>wait for breakpoint to be hit in debugger</li>
	<li>step through code</li>
	<li>based on your runtime debugging inspection, decide what you want to change in the code</li>
	<li>kill the master and regionserver by doing control-C in each service's shell.</li>
	<li>if desired, <a href="#reinit">re-initialize the <code>hbase/</code> directory in HDFS</a>.
	<li>goto step 1</li>
      </ol>

      <h2 id="edit">Editing code</h2>

      <p>Use whatever editor you like but you should respect
      the <a href="">Hbase coding conventions</a>. Here are some links
      to documentation for various popular editors and how to
      configure them to respect these conventions.</p>

      <h2 id="compile">Compilation</h2>

      <p>
      In a shell, you can leave the following running while you work on your code:
      </p>

      <pre class="block">
<span class="input">while ( true ) do mvn compile && sleep 5 ; done</span>
      </pre>

      <p>This ensures that you always have the latest code compiled and ready to run, and you'll notice compiler errors as you follow the output in one window, while editing your code in another window.</p>

      <p>Note that we do only <code>mvn compile</code>: only the <code>.class</code>es are generated, not <code>.jar</code>s.

	<h2 id="run">Running Hbase daemons</h2>

	<h3>Master</h3>
	<pre class="block session">
	  bin/hbase master start
	</pre>

	<h3>Regionserver</h3>
	<pre class="block session">
	  bin/hbase regionserver start
	</pre>

      <p>
	For development purposes, you only need one master and one
	regionserver. Each of these should be run in a separate shell.
	If you press <code>control-C</code> in one of these shells,
	you'll send a terminate signal to the respective service,
	which is good, so that you can easily stop and start the services</a>.

      <h2 id="reinit">Reinitializing</h2> 

      <p>In between debugging runs, you may want to reset your Hbase
      to clear any state left by your debugging session.  Note that
      you'll confuse and probably terminate your Hbase master and
      regionserver if you do either of these while they are running.</p>

      <h3>Hbase</h3>
      
      <p>This will wipe your HBase data directory (on HDFS) clean:</p>
      
      <pre class="block session">
ekoontz@ubuntu:~/hadoop$ bin/hadoop fs -rmr hdfs://namenode/hbase
      </pre>
      
      <p>Where <code>namenode</code> is the hostname of your namenode.</p>

      <h3>Zookeeper</h3>
      <pre class="block session">
ekoontz@ubuntu:~$ zookeeper/bin/zkCli.sh -server zookeeper rmr /hbase
      </pre>

      <p>Where <code>zookeeper</code> is the hostname of your
      zookeeper.</p>

      <h1>Runtime inspection of HBase</h1>
    <p>
      I prefer <a href="http://www.jetbrains.com/idea/">Intellij IDEA</a> rather than <a href="http://eclipse.org">Eclipse</a>, but would welcome
      someone writing an Eclipse guide and adding it here (using
      CC:attribute licence).
    </p>
        <h2>Intellij</h2>


        <h3 id="attach">Intellij: Attaching to remote instances</h3>
   
	<p>
	Intellij uses the Java debug machinery (enabled with):

	<pre class="block">
	  -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5006
	</pre>
	
	<p>
	to interactively debug Java processes running on remote
	machines. This is great because it lets you run your desktop
	operating system of choice (be it Mac OS X, Linux, or Windows)
	as your development environment, but still run your compiled
	runtime on Linux, which is required if you want to run HBase
	according to its <a href="http://hbase.org/">official
	Recommendations</a>.
	</p>

	<p>Note, however, that you will not be able to compile within
	Intellij: you must open a shell on the machine you want to run
	HBase on, and run <code>mvn compile</code> there.
	</p>

	<h1>Automated Testing</h1>

	<p>As you add new functionality to Hbase, be sure to add tests
	to the <code>src/tests</code> directory, and to make sure
	existing tests pass, using <code>mvn test</code>.</p>

	<p>Let's say you've just added a new
	class, <code>org.apache.hadoop.hbase.ipc.foo</code>. Your test
	should probably go
	in <code>hbase/src/test/java/ipc/TestFoo.java</code>. You'll
	be iteratively running your test and want to only run that
	test until it's ready to commit. To cause Maven to only run
	your test, you would do:</p>

	<pre class="block session">
[~/hbase] $ <span class="input">mvn -Dtest=TestFoo test</span>
	</pre>

	<h2>Using EC2 for testing</h2>
	<p>Running all unit tests takes a long time; therefore, you
	might want a fast, dedicated server, or on Amazon EC2 large
	(or better) instance.</p>

        <h1>Common Problems and How to Solve Them</h1>

        <p><i>Note that some of the solutions below wipe out all existing
        data in your HBase and or HDFS file system. Again, this guide
        is for development, not production, use of HBase, and your
        data should only be for testing purposes and stored separately
        if you care about preserving it.</i></p>

        <h2>Interactions with debugger: Pausing and Restarting HBase
        Processes</h2>

        <h3>Regionserver</h3>

        <p>If you attach to a running regionserver with your debugger,
        you might be stepping through the code for an extended amount
        of time. This will exceed a certain timeout (zookeeper
        lease(?)) and you'll make the master think you're dead.</p>

        <p>When you try to continue, the regionserver will shut itself
        down. You may find that the master shuts down too (need to
        make sure about this). If this occurs you may find that
        starting the master, then starting the regionserver, causes
        the master to shut down. Then, you then start the master,
        which shuts the regionserver down. The way out of this
        deadlock is to reinitialize zookeeper:</p>

	<pre class="block session">
[~/hbase] $ <span class="input">alias zkrm=&quot;~/zookeeper/bin/zkCli.sh -server zookeeper rmr /hbase&quot;</span>
[~/hbase] $ <span class="input">zkrm</span>
	</pre>

        <h3>Master</h3>

<p>Operating system pauses can cause zookeeper session loss:</p>
<div class="halfpage">
	<pre class="block screen halfpage">
10/09/28 12:09:38 DEBUG ipc.HBaseServer: IPC Server handler 17 on 60000: has #1746 from 192.168.56.10:48114
10/09/28 12:09:38 DEBUG ipc.HBaseServer: Served: regionServerReport queueTime= 1 procesingTime= 1
10/09/28 12:09:38 DEBUG ipc.HBaseServer: IPC Server Responder: responding to #1746 from 192.168.56.10:48114
10/09/28 12:09:38 DEBUG ipc.HBaseServer: IPC Server Responder: responding to #1746 from 192.168.56.10:48114 Wrote 8 bytes.
... Guest OS is paused by Host OS ...


... Guest OS is resumed by Host OS ...
10/09/28 12:42:46 DEBUG ipc.HBaseServer: IPC Server listener on 60000: disconnecting client 192.168.56.10. Number of active connections: 1
10/09/28 12:42:46 WARN util.Sleeper: We slept 2045771ms instead of 60000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://wiki.apache.org/hadoop/Hbase/Troubleshooting#A9
10/09/28 12:42:46 INFO master.ServerManager: regionservers=1, averageload=3, deadservers=[ubuntu.foofers.org,60020,1285695293102]
10/09/28 12:42:46 WARN util.Sleeper: We slept 2045698ms instead of 60000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://wiki.apache.org/hadoop/Hbase/Troubleshooting#A9
10/09/28 12:42:46 WARN util.Sleeper: We slept 2283867ms instead of 300000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://wiki.apache.org/hadoop/Hbase/Troubleshooting#A9
10/09/28 12:42:46 DEBUG master.HMaster: Not running balancer because dead regionserver processing
10/09/28 12:42:46 WARN util.Sleeper: We slept 1987458ms instead of 1000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://wiki.apache.org/hadoop/Hbase/Troubleshooting#A9
10/09/28 12:42:46 DEBUG master.LoadBalancer: Skipping load balancing.  servers=1 regions=3 average=3.0 mostloaded=3 leastloaded=3
10/09/28 12:42:46 WARN util.Sleeper: We slept 2015474ms instead of 30000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://wiki.apache.org/hadoop/Hbase/Troubleshooting#A9
10/09/28 12:42:47 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x12b59517df6000e, likely server has closed socket, closing socket connection and attempting reconnect
10/09/28 12:42:47 INFO zookeeper.ClientCnxn: Client session timed out, have not heard from server in 1988340ms for sessionid 0x12b59517df6000d, closing socket connection and attempting reconnect
10/09/28 12:42:47 INFO zookeeper.ZooKeeperWatcher: hconnection-0x12b59517df6000e Received Disconnected from ZooKeeper, ignoring
10/09/28 12:42:47 INFO zookeeper.ZooKeeperWatcher: master-0x12b59517df6000d Received Disconnected from ZooKeeper, ignoring
10/09/28 12:42:48 DEBUG ipc.HBaseServer: Server connection from 192.168.56.10:36272; # active connections: 1; # queued calls: 0
10/09/28 12:42:48 INFO zookeeper.ClientCnxn: Opening socket connection to server zookeeper.foofers.org/192.168.56.10:2181
10/09/28 12:42:48 INFO zookeeper.ClientCnxn: Socket connection established to zookeeper.foofers.org/192.168.56.10:2181, initiating session
10/09/28 12:42:48 DEBUG ipc.HBaseServer:  got #1747
10/09/28 12:42:48 DEBUG ipc.HBaseServer: IPC Server handler 18 on 60000: has #1747 from 192.168.56.10:36272
10/09/28 12:42:48 DEBUG ipc.HBaseServer: Served: regionServerReport queueTime= 16 procesingTime= 0
10/09/28 12:42:48 DEBUG ipc.HBaseServer: IPC Server Responder: responding to #1747 from 192.168.56.10:36272
10/09/28 12:42:48 DEBUG ipc.HBaseServer: IPC Server Responder: responding to #1747 from 192.168.56.10:36272 Wrote 8 bytes.
10/09/28 12:42:48 INFO zookeeper.ClientCnxn: Opening socket connection to server zookeeper.foofers.org/192.168.56.10:2181
10/09/28 12:42:48 INFO zookeeper.ClientCnxn: Socket connection established to zookeeper.foofers.org/192.168.56.10:2181, initiating session
10/09/28 12:42:49 ERROR zookeeper.ZooKeeperWatcher: hconnection-0x12b59517df6000e Received Expired from ZooKeeper, aborting server
10/09/28 12:42:49 FATAL client.HConnectionManager$HConnectionImplementation: hconnection-0x12b59517df6000e Received Expired from ZooKeeper, aborting server
10/09/28 12:42:49 INFO zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x12b59517df6000d has expired, closing socket connection
10/09/28 12:42:49 ERROR zookeeper.ZooKeeperWatcher: master-0x12b59517df6000d Received Expired from ZooKeeper, aborting server
10/09/28 12:42:49 FATAL master.HMaster: master-0x12b59517df6000d Received Expired from ZooKeeper, aborting server
10/09/28 12:42:49 INFO master.HMaster: Aborting
10/09/28 12:42:49 INFO zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x12b59517df6000e has expired, closing socket connection
10/09/28 12:42:49 INFO master.HMaster: Stopping infoServer
10/09/28 12:42:49 INFO mortbay.log: Stopped SelectChannelConnector@0.0.0.0:60010
10/09/28 12:42:50 INFO ipc.HBaseServer: Stopping server on 60000
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 0 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 1 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 2 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 3 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 4 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 5 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 6 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 7 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 8 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 9 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 10 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 11 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 12 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 13 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 14 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 15 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 16 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 17 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 19 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: Stopping IPC Server listener on 60000
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 24 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 23 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 20 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 22 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 21 on 60000: exiting
10/09/28 12:42:50 INFO ipc.HBaseServer: IPC Server handler 18 on 60000: exiting
10/09/28 12:42:50 DEBUG ipc.HBaseServer: Checking for old call responses.
10/09/28 12:42:50 INFO ipc.HBaseServer: Stopping IPC Server Responder
10/09/28 12:42:50 INFO master.HMaster$1: ubuntu.foofers.org:60000-balancerChore exiting
10/09/28 12:42:50 WARN zookeeper.ZKUtil: master-0x12b59517df6000d Unable to get data of znode /hbase/master
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/master
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:118)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:921)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAndWatch(ZKUtil.java:492)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAsAddress(ZKUtil.java:565)
	at org.apache.hadoop.hbase.master.ActiveMasterManager.stop(ActiveMasterManager.java:179)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:351)
10/09/28 12:42:50 ERROR zookeeper.ZooKeeperWatcher: master-0x12b59517df6000d Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/master
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:118)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:921)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAndWatch(ZKUtil.java:492)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAsAddress(ZKUtil.java:565)
	at org.apache.hadoop.hbase.master.ActiveMasterManager.stop(ActiveMasterManager.java:179)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:351)
10/09/28 12:42:50 ERROR master.ActiveMasterManager: master-0x12b59517df6000d Error deleting our own master address node
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/master
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:118)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:921)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAndWatch(ZKUtil.java:492)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getDataAsAddress(ZKUtil.java:565)
	at org.apache.hadoop.hbase.master.ActiveMasterManager.stop(ActiveMasterManager.java:179)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:351)
10/09/28 12:42:50 DEBUG client.HConnectionManager$HConnectionImplementation: Closed zookeeper sessionid=0x12b59517df6000e
10/09/28 12:42:50 INFO master.HMaster: HMaster main thread exiting
ekoontz@ubuntu:~/hbase$ 
	</pre>
</div>

        <h2>HDFS</h2>

        <h3>Hadoop Filesystem Corruption: <code>InconsistentFSStateException</code></h3>

        <p>
          This might happen if you shut down all of of your Hadoop
          namenodes and datanodes, and then try to bring them up again by doing:
          <code>bin/hadoop namenode</code> and <code>bin/hadoop datanode</code>.
        </p>

        <p>
          Here's a screenshot showing output from such a situation:
        </p>
        
        <div class="screenshot">
          <a href="inconsistentfsstate.png"><img width="75%" src="inconsistentfsstate.png"/></a>
        </div>

        <h4>Solution</h4>

        <p><code>rm -rf /tmp/hadoop-$USER</code></p>

        <h3>Hadoop Filesystem <code>'Incompatible build'</code> errors at startup</h3>

        <h4>Solution on namenode</h4>

        <p><code>bin/hadoop namenode -format</code>, or,
        if you want be more low-level, do the following (the "Solution on datanodes" section)</p>
        <h4>Solution on datanodes</h4>
        <p>On datanodes: <code>rm -rf /tmp/hadoop-$USER</code></p>

        <h3>'<tt>UnregisteredDatanodeException: Unregistered data node</tt>' errors on namenode</tt></h3>

        <p>This can happen if a datanode continues running while a
        namenode is rebooted. The datanode successfully reconnects
        when the namenode comes up, but the namenode doesn't recognize
        this datanode any more.</p>

        <h4>Solution</h4>

        <p>On the datanode, shutdown the datanode process and do: <code>rm -rf /tmp/hadoop-$USER</code></p>

        <h2>Master-specific startup problems</h2>

        <h3>Couldnt start ZK at requested address of 2181, instead got: 2182. Aborting. Why? Because clients (eg shell) wont be able to find this ZK quorum</h3>

        <p>Please see the gist above in the section <a href="#config">Configuration settings</a> which
        fixes this by setting <tt>hbase.zookeeper.quorum</tt>.</p>

        <h2>Region-specific startup problems</h2>

        <h3>regionserver.HRegionServerCommandLine: Not starting a distinct region server because hbase.cluster.distributed is false</h3>
        <p>Please see the gist above in the section <a href="#config">Configuration settings</a> which
        fixes this by setting <tt>hbase.cluster.distributed</tt> to <tt>true</tt>.</p>
          
        <h1>References</h1>
        <table class="references">
          <tr>
            <th/>
            <th>Title</th>
            <th>Author</th>
          </tr>
          <tr>
            <td/>
            <td><a href="http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Multi-Node_Cluster)">Running Hadoop On Ubuntu Linux (Multi-Node Cluster)</a></td>
            <td>Michael Noll</td>
          </tr>
          <tr>
            <td/>
            <td><a href="http://www.michael-noll.com/wiki/Running_Hadoop_On_Ubuntu_Linux_(Single-Node_Cluster)">Running Hadoop On Ubuntu Linux (Single-Node Cluster)</a></td>
            <td>Michael Noll</td>
          </tr>
        </table>

  </body>
</html>
